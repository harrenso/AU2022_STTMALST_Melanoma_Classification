{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melanoma Classification - Data Preperation\n",
    "<b>Data Source:</b>\n",
    "* https://challenge.isic-archive.com/data/#2019\n",
    "* https://challenge.isic-archive.com/data/#2020\n",
    "\n",
    "<b>Contents of this notebook</b>\n",
    "1. Load groundtruth data\n",
    "2. Combine 2019 and 2020 ISIC dataset\n",
    "3. Remove duplicates \n",
    "4. Train Test Validation split\n",
    "5. Save groundtruth data\n",
    "6. Download and sort images \n",
    "\n",
    "Please note that up until step 5, no data will actually be downloaded as in saved to the desk. Further, all operations will be performed only on the csv files for performance issues up until step 6, where all previous operations will be performed on the images in one step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load groundtruth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ISIC 2020 Groundtruth\n",
      "Loading ISIC 2019 Groundtruth\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"Loading ISIC 2020 Groundtruth\")\n",
    "url_2020 = \"https://isic-challenge-data.s3.amazonaws.com/2020/ISIC_2020_Training_GroundTruth_v2.csv\"\n",
    "df_2020 =  pd.read_csv(url_2020)\n",
    "\n",
    "print(\"Loading ISIC 2019 Groundtruth\")\n",
    "url_2019 = \"https://isic-challenge-data.s3.amazonaws.com/2019/ISIC_2019_Training_GroundTruth.csv\"\n",
    "df_2019 =  pd.read_csv(url_2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Combine 2019 and 2020 ISIC dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare available columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before transformation:\n",
      "2020 ISIC:\t 9 columns available: ['image_name', 'patient_id', 'lesion_id', 'sex', 'age_approx', 'anatom_site_general_challenge', 'diagnosis', 'benign_malignant', 'target']\n",
      "2019 ISIC:\t 10 columns available: ['image', 'MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC', 'UNK']\n"
     ]
    }
   ],
   "source": [
    "def print_avail_columns(name, df):\n",
    "    col = df.columns.values.tolist()\n",
    "    print(\"%s:\\t %i columns available: %s\" %(name, len(col), col))\n",
    "\n",
    "print(\"Before transformation:\")\n",
    "print_avail_columns(\"2020 ISIC\", df_2020)\n",
    "print_avail_columns(\"2019 ISIC\", df_2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform into the same format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After transformation:\n",
      "2020 ISIC:\t 2 columns available: ['image_name', 'target']\n",
      "2019 ISIC:\t 2 columns available: ['image_name', 'target']\n"
     ]
    }
   ],
   "source": [
    "df_2020 = df_2020[['image_name', 'target']]\n",
    "\n",
    "df_2019['target'] = df_2019.apply(lambda row: row.MEL == True, axis = 1)\n",
    "df_2019 = df_2019[['image', 'target']]\n",
    "df_2019 = df_2019.rename(columns = {'image':'image_name'})\n",
    "\n",
    "print(\"After transformation:\")\n",
    "print_avail_columns(\"2020 ISIC\", df_2020)\n",
    "print_avail_columns(\"2019 ISIC\", df_2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020 ISIC:\t 33126 total samples \t 584 melanoma samples \t 1.76 % melanoma percentage\n",
      "2019 ISIC:\t 25331 total samples \t 4522 melanoma samples \t 17.85 % melanoma percentage\n"
     ]
    }
   ],
   "source": [
    "def print_melanoma_count(name, df):\n",
    "    count = len(df.index)\n",
    "    count_melanoma = len(df[df['target']==True])\n",
    "    percentage_melanoma = count_melanoma/count\n",
    "    print(\"%s:\\t %i total samples \\t %i melanoma samples \\t %0.2f %% melanoma percentage\" \n",
    "          %(name, count, count_melanoma, percentage_melanoma*100))\n",
    "\n",
    "print_melanoma_count(\"2020 ISIC\", df_2020)\n",
    "print_melanoma_count(\"2019 ISIC\", df_2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined ISIC:\t 58457 total samples \t 5106 melanoma samples \t 8.73 % melanoma percentage\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df_2020, df_2019]).drop_duplicates()\n",
    "print_melanoma_count(\"Combined ISIC\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 425 duplicate pictures\n",
      "There are 58457 images in total\n",
      "After dropping the duplicates, there are 33126 images in total\n",
      "\n",
      "Duplicate free, combined ISIC:\t 58032 total samples \t 5103 melanoma samples \t 8.79 % melanoma percentage\n"
     ]
    }
   ],
   "source": [
    "df_duplicates_2020 = pd.read_csv('https://isic-challenge-data.s3.amazonaws.com/2020/ISIC_2020_Training_Duplicates.csv')\n",
    "img_to_drop = df_duplicates_2020.image_name_1.values.tolist()\n",
    "\n",
    "print(\"There are %i duplicate pictures\" %len(df_duplicates_2020.index))\n",
    "print(\"There are %i images in total\" %len(df.index))\n",
    "\n",
    "df = df[df.image_name.isin(img_to_drop) == False]\n",
    "print(\"After dropping the duplicates, there are %i images in total\" %len(df_2020.index))\n",
    "\n",
    "print_melanoma_count(\"\\nDuplicate free, combined ISIC\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Test Validation split\n",
    "<b>Training Set</b>\n",
    "* 80%\n",
    "* Used to train the learning algorithm\n",
    "\n",
    "<b>Validation</b>\n",
    "* Part of training set that is held out (10% of overall data)\n",
    "* Used to evaluate different algorithms and hyperparameter settings\n",
    "\n",
    "<b>Test</b>\n",
    "* 10%\n",
    "* Used to test the model and estimate ist performance in application\n",
    "* Will <b>not</b> be used for training under no circumstances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\t 46425 total samples \t 4096 melanoma samples \t 8.82 % melanoma percentage\n",
      "Valid set:\t 5803 total samples \t 526 melanoma samples \t 9.06 % melanoma percentage\n",
      "Test set:\t 5804 total samples \t 481 melanoma samples \t 8.29 % melanoma percentage\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "X = df.drop(columns = ['target']).copy()\n",
    "y = df[['target']]\n",
    "\n",
    "train_size=0.8 # 80% training set\n",
    "X_train, X_remaining, y_train, y_remaining = train_test_split(X, y, train_size=train_size, random_state=random_state)\n",
    "\n",
    "test_size = 0.5 # 50% of remaining 20% -> 10%\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_remaining, y_remaining, test_size=test_size, random_state=random_state)\n",
    "\n",
    "train = pd.concat([X_train.reset_index(drop=True), y_train.reset_index(drop=True)], axis=1, join='inner')\n",
    "valid = pd.concat([X_valid.reset_index(drop=True), y_valid.reset_index(drop=True)], axis=1, join='inner')\n",
    "test = pd.concat([X_test.reset_index(drop=True), y_test.reset_index(drop=True)], axis=1, join='inner')\n",
    "\n",
    "print_melanoma_count(\"Train set\", train)\n",
    "print_melanoma_count(\"Valid set\", valid)\n",
    "print_melanoma_count(\"Test set\", test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Saving groundtruth to computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new directory data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data_root = 'data'\n",
    "if not os.path.exists(data_root): \n",
    "  os.makedirs(data_root)\n",
    "  print(\"Created new directory %s\" %data_root)\n",
    "    \n",
    "train.to_csv(data_root + \"/ISIC_2020_2019_train.csv\")\n",
    "valid.to_csv(data_root + \"/ISIC_2020_2019_valid.csv\")\n",
    "test.to_csv(data_root + \"/ISIC_2020_2019_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Saving images to computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import datetime\n",
    "import io\n",
    "import requests\n",
    "\n",
    "def sort_zip_file(zip_file, zip_namelist, img_names, dest):\n",
    "    print(\"Sorting into %s\" %dest)\n",
    "    \n",
    "    dest = data_root + \"/\" + dest\n",
    "    if not os.path.exists(dest): \n",
    "      os.makedirs(dest)\n",
    "      print(\"Created new directory %s\" %dest)\n",
    "    \n",
    "    print(\"Started sorting at: \", datetime.datetime.now())\n",
    "    folder_name = zip_namelist[0].partition(\"/\")[0]\n",
    "    common = [folder_name + \"/\" + filename + \".jpg\" for filename in img_names if folder_name + \"/\" + filename + \".jpg\" in zip_namelist]\n",
    "    for filename in common:\n",
    "        zip_file.extract(filename, dest)\n",
    "    print(\"Finished sorting at: \", datetime.datetime.now())\n",
    "\n",
    "def download_and_sort_img(src, img_name_list, dest_list):  \n",
    "    file_name = data_root + \"/images.zip\"\n",
    "     \n",
    "    print(\"Downloading and sorting %s\" %src)\n",
    "    print(\"Started download at: \", datetime.datetime.now())\n",
    "    with open(file_name,\"wb\") as file:\n",
    "        for chunk in requests.get(src, stream = True).iter_content(chunk_size=1024):\n",
    "            if chunk:\n",
    "                file.write(chunk)\n",
    "    print(\"Finished download at: \", datetime.datetime.now())\n",
    "\n",
    "    with ZipFile(file_name, 'r') as zip_file:\n",
    "        zip_namelist = zip_file.namelist()\n",
    "        for i in range(len(img_name_list)):\n",
    "            sort_zip_file(zip_file, zip_namelist, img_name_list[i], dest_list[i])\n",
    "    \n",
    "    print(\"Removing %s .zip file\" %file_name)\n",
    "    print(\"Started removing at: \", datetime.datetime.now())\n",
    "    os.remove(file_name)\n",
    "    print(\"Finished removing at: \", datetime.datetime.now())\n",
    "        \n",
    "train_img = X_train[\"image_name\"].values.tolist()\n",
    "test_img = X_test[\"image_name\"].values.tolist()\n",
    "valid_img = X_valid[\"image_name\"].values.tolist()\n",
    "\n",
    "img_name_list = [train_img, test_img, valid_img]\n",
    "dest_list = [\"train\", \"test\", \"valid\"]\n",
    "\n",
    "img_2020 = 'https://isic-challenge-data.s3.amazonaws.com/2020/ISIC_2020_Training_JPEG.zip'\n",
    "img_2019 = 'https://isic-challenge-data.s3.amazonaws.com/2019/ISIC_2019_Training_Input.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and sorting https://isic-challenge-data.s3.amazonaws.com/2019/ISIC_2019_Training_Input.zip\n",
      "Started download at:  2022-10-12 23:08:35.010846\n",
      "Finished download at:  2022-10-12 23:31:19.150132\n",
      "Sorting into train\n",
      "Created new directory data/train\n",
      "Started sorting at:  2022-10-12 23:31:19.698541\n",
      "Finished sorting at:  2022-10-12 23:49:01.005239\n",
      "Sorting into test\n",
      "Created new directory data/test\n",
      "Started sorting at:  2022-10-12 23:49:01.036370\n",
      "Finished sorting at:  2022-10-12 23:51:10.183360\n",
      "Sorting into valid\n",
      "Created new directory data/valid\n",
      "Started sorting at:  2022-10-12 23:51:10.198988\n",
      "Finished sorting at:  2022-10-12 23:53:13.783618\n",
      "Removing data/images.zip .zip file\n",
      "Started removing at:  2022-10-12 23:53:13.783618\n",
      "Finished removing at:  2022-10-12 23:53:13.783618\n"
     ]
    }
   ],
   "source": [
    "download_and_sort_img(img_2019, img_name_list, dest_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and sorting https://isic-challenge-data.s3.amazonaws.com/2020/ISIC_2020_Training_JPEG.zip\n",
      "Started download at:  2022-10-12 23:53:13.844418\n",
      "Finished download at:  2022-10-13 00:49:51.722518\n",
      "Sorting into train\n",
      "Started sorting at:  2022-10-13 00:49:52.558686\n",
      "Finished sorting at:  2022-10-13 01:24:55.859148\n",
      "Sorting into test\n",
      "Started sorting at:  2022-10-13 01:24:55.859148\n",
      "Finished sorting at:  2022-10-13 01:29:01.797043\n",
      "Sorting into valid\n",
      "Started sorting at:  2022-10-13 01:29:01.797043\n",
      "Finished sorting at:  2022-10-13 01:33:07.350322\n",
      "Removing data/images.zip .zip file\n",
      "Started removing at:  2022-10-13 01:33:07.365717\n",
      "Finished removing at:  2022-10-13 01:33:07.365717\n"
     ]
    }
   ],
   "source": [
    "download_and_sort_img(img_2020, img_name_list, dest_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1d01c6bf3e9d205d38e3a736a612358a4609254e46bf94dc685129c2f8b8b6c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melanoma Classification Model - Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up for importing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Random State\n",
    " Please use the following random state for all methods that may take a random state in order to achieve reproducable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import random_state\n",
    "random_state = random_state() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export Config\n",
    "You may configure \n",
    "- whether the results shall be exported (export_results)\n",
    "- where the results will be exported to\n",
    "\n",
    "The default folder \"export\" will not be tracked by git in order to avoid flooding the repository with w.i.p. results. If you want to save a result on github, please rename it including the type of model and the date and move the picture to another folder :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_results = True\n",
    "export_folder = 'export'\n",
    "\n",
    "date_format = \"%d%m%Y%H%M%S\" # timestamp format in exported files\n",
    "if export_results:\n",
    "    import datetime\n",
    "    import os\n",
    "    if not os.path.exists(export_folder): \n",
    "      os.makedirs(export_folder)\n",
    "      print(\"Created new directory %s\" %export_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get image paths\n",
    "You may adjust the number of images loaded in order to run models more quickly on your private computer. Note hoewever that the less images you use the worse the predictions will likely be. \n",
    "\n",
    "For developing models on the cluster the max_images parameter should be removed. Instead call the method get_all_img_paths(img_folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import get_img_paths\n",
    "\n",
    "img_folder_train = \"data/train\" # change this to the folder including your images!\n",
    "img_folder_test = \"data/test\"\n",
    "max_images_train = 800\n",
    "max_images_test = 100\n",
    "\n",
    "img_paths_train = get_img_paths(img_folder_train, max_images_train) \n",
    "img_paths_test = get_img_paths(img_folder_test, max_images_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data\n",
    "Loads the images specified in img_paths into a data frame. This includes resizing the images and flattening them into an array and may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import load_data\n",
    "\n",
    "groundtruth_file_train = \"data/ISIC_2020_2019_train.csv\" # change this to the path where you have your data!\n",
    "groundtruth_file_test = \"data/ISIC_2020_2019_test.csv\"\n",
    "\n",
    "df_train = load_data(img_paths_train, groundtruth_file_train)\n",
    "df_test = load_data(img_paths_test, groundtruth_file_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into target and predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import split_predictors_target\n",
    "\n",
    "X_train, y_train = split_predictors_target(df_train) \n",
    "X_test, y_test = split_predictors_target(df_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction, grid search and training the model\n",
    "Function performing feature extraction, grid search, training and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from utilities import display_results\n",
    "from utilities import display_interesting_results\n",
    "\n",
    "\n",
    "def feature_selection_prediction(method,x_train, y_train,x_test, y_test):\n",
    "    x_train_reduced = method.fit(x_train, y_train).transform(x_train)\n",
    "    param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf','poly']} \n",
    "    model = GridSearchCV(svm.SVC(), param_grid, refit = True, verbose = 0)\n",
    "    model.fit(x_train_reduced,y_train)\n",
    "    print(f'GridSearch best params after tuning={ model.best_params_}')\n",
    "    print(f'GridSearch model after tuning={model.best_estimator_}')  \n",
    "    x_test_reduced = method.fit(x_test, y_test).transform(x_test)\n",
    "    y_pred = model.predict(x_test_reduced)\n",
    "    \n",
    "    ## print classification result\n",
    "    report = classification_report(y_test, y_pred, digits=4)\n",
    "    print(f'\\nClassification_report=\\n{report}\\n')\n",
    "    if export_results:\n",
    "        file = open(export_folder + \"/classification_report_\"+datetime.datetime.now().strftime(date_format)+\".txt\", 'w')\n",
    "        file.write(report)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing and training of four different feature extraction methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Principle Component Analysis\n",
      "\n",
      "GridSearch best params after tuning={'C': 0.1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "GridSearch model after tuning=SVC(C=0.1, gamma=0.001, kernel='poly')\n",
      "\n",
      "Classification_report=\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8061    1.0000    0.8927        79\n",
      "           1     1.0000    0.0952    0.1739        21\n",
      "\n",
      "    accuracy                         0.8100       100\n",
      "   macro avg     0.9031    0.5476    0.5333       100\n",
      "weighted avg     0.8468    0.8100    0.7417       100\n",
      "\n",
      "\n",
      "Independent Component Analysis\n",
      "\n",
      "GridSearch best params after tuning={'C': 100, 'gamma': 1, 'kernel': 'rbf'}\n",
      "GridSearch model after tuning=SVC(C=100, gamma=1)\n",
      "\n",
      "Classification_report=\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7907    0.8608    0.8242        79\n",
      "           1     0.2143    0.1429    0.1714        21\n",
      "\n",
      "    accuracy                         0.7100       100\n",
      "   macro avg     0.5025    0.5018    0.4978       100\n",
      "weighted avg     0.6697    0.7100    0.6872       100\n",
      "\n",
      "\n",
      "Linear Discriminant Analysis\n",
      "\n",
      "GridSearch best params after tuning={'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "GridSearch model after tuning=SVC(C=100, gamma=0.01)\n",
      "\n",
      "Classification_report=\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8941    0.9620    0.9268        79\n",
      "           1     0.8000    0.5714    0.6667        21\n",
      "\n",
      "    accuracy                         0.8800       100\n",
      "   macro avg     0.8471    0.7667    0.7967       100\n",
      "weighted avg     0.8744    0.8800    0.8722       100\n",
      "\n",
      "\n",
      "Locally Linear Embedding\n",
      "GridSearch best params after tuning={'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "GridSearch model after tuning=SVC(C=0.1, gamma=1)\n",
      "\n",
      "Classification_report=\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7900    1.0000    0.8827        79\n",
      "           1     0.0000    0.0000    0.0000        21\n",
      "\n",
      "    accuracy                         0.7900       100\n",
      "   macro avg     0.3950    0.5000    0.4413       100\n",
      "weighted avg     0.6241    0.7900    0.6973       100\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aneta\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aneta\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aneta\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Principle Component Analysis\\n\")\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=20)\n",
    "feature_selection_prediction(pca, X_train, y_train,X_test, y_test)\n",
    "\n",
    "print(\"Independent Component Analysis\\n\")\n",
    "from sklearn.decomposition import FastICA\n",
    "ica = FastICA(n_components=20,max_iter = 500)\n",
    "feature_selection_prediction(ica, X_train, y_train,X_test, y_test)\n",
    "\n",
    "print(\"Linear Discriminant Analysis\\n\")\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "feature_selection_prediction(lda, X_train, y_train,X_test, y_test)\n",
    "\n",
    "print(\"Locally Linear Embedding\")\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "embedding = LocallyLinearEmbedding(n_components=2)\n",
    "feature_selection_prediction(embedding, X_train, y_train,X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melanoma Classification - Data Investigation\n",
    "Data Source: https://challenge2020.isic-archive.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Downloading the data\n",
    "This step will take a while. Please be patient and do not aboard the project prematurely. We are downloading 25 GB. Please make sure you have enough space for this large amount of data.\n",
    "\n",
    "If you have already previously downloaded the data, please move it into a folder called \"data\" in the directory of this project, so that the following steps can run without a problem.\n",
    "\n",
    "The structure after this step will be as followed:\n",
    "<pre>\n",
    "data_investigation.ipynb\n",
    "data\n",
    "|---ISIC_2020_Training_Duplicates.csv\n",
    "|---ISIC_2020_Training_GroundTruth_v2.csv\n",
    "|---ISIC_2020_Training_JPEG.zip\n",
    "</pre>\n",
    "In the next step the images will be unzipped. Continue with step 2.\n",
    "\n",
    "If you have already unzipped the data the structure should now look like this: \n",
    "<pre>\n",
    "data_investigation.ipynb\n",
    "data\n",
    "|---ISIC_2020_Training_Duplicates.csv\n",
    "|---ISIC_2020_Training_GroundTruth_v2.csv\n",
    "|---ISIC_2020_Training_JPEG\n",
    "    |---train\n",
    "        |---ISIC_0099474.jpg\n",
    "        |---...\n",
    "</pre>\n",
    "If you are at this data structure please continue with step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new directory for data\n",
      "Downloading ISIC img data\n",
      "Downloading ISIC meta data\n",
      "Dowloading ISIC duplicate image list\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11500"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests \n",
    "\n",
    "path = 'data'\n",
    "if not os.path.exists(path): \n",
    "  os.makedirs(path)\n",
    "  print(\"Created new directory for data\")\n",
    "\n",
    "print('Downloading ISIC img data')\n",
    "img_data = 'https://isic-challenge-data.s3.amazonaws.com/2020/ISIC_2020_Training_JPEG.zip'\n",
    "r = requests.get(img_data, allow_redirects=True, stream = True)\n",
    "with open(\"data/ISIC_2020_Training_JPEG.zip\",\"wb\") as file:\n",
    "    for chunk in r.iter_content(chunk_size=1024):\n",
    "         if chunk:\n",
    "             file.write(chunk)\n",
    "\n",
    "print('Downloading ISIC meta data')\n",
    "meta_data = 'https://isic-challenge-data.s3.amazonaws.com/2020/ISIC_2020_Training_GroundTruth_v2.csv'\n",
    "r = requests.get(meta_data, allow_redirects=True)\n",
    "open('data/ISIC_2020_Training_GroundTruth_v2.csv', 'wb').write(r.content)\n",
    "\n",
    "print('Downloading ISIC duplicate image list')\n",
    "duplicate_list_data = 'https://isic-challenge-data.s3.amazonaws.com/2020/ISIC_2020_Training_Duplicates.csv'\n",
    "r = requests.get(duplicate_list_data, allow_redirects=True)\n",
    "open('data/ISIC_2020_Training_Duplicates.csv', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Unzipping downloaded data\n",
    "The images are included in a .zip file. In order to work with the images, we have to unzip the data.\n",
    "\n",
    "This step will also take quite a while. Be patient :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping Image Data\n",
      "Finished unzipping images\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "print(\"Unzipping Image Data\")\n",
    "with ZipFile(\"data/ISIC_2020_Training_JPEG.zip\", 'r') as zObject:\n",
    "    zObject.extractall(path=\"data/ISIC_2020_Training_JPEG\")\n",
    "print(\"Finished unzipping images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filtering duplicates\n",
    "The data includes some duplicates.These are stored in the file \"data/ISIC_2020_Training_Duplicates.csv\".\n",
    "We do not want to train on duplicate data and will therefore remove these images from our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 425 duplicate pictures in the data\n",
      "There are 33126 images in total in the meta-data file ('ground-truth')\n",
      "There are 33126 images on the hard-drive\n",
      "Dropping images in ground truth\n",
      "After dropping the duplicates, there are 32701 images in total in the meta-data file ('ground-truth')\n",
      "Deleting duplicate images from the hard-drive\n",
      "There are now 32701 images on the hard-drive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df_duplicates = pd.read_csv(\"data/ISIC_2020_Training_Duplicates.csv\")\n",
    "df_groundtruth = pd.read_csv(\"data/ISIC_2020_Training_GroundTruth_v2.csv\")\n",
    "img_path = 'data/ISIC_2020_Training_JPEG/train'\n",
    "\n",
    "print(\"There are %i duplicate pictures in the data\" %len(df_duplicates.index))\n",
    "print(\"There are %i images in total in the meta-data file ('ground-truth')\" %len(df_groundtruth.index))\n",
    "print(\"There are %i images on the hard-drive\" %len([name for name in os.listdir(img_path) if os.path.isfile(os.path.join(img_path, name))]))\n",
    "\n",
    "img_to_drop = df_duplicates.image_name_1.values.tolist()\n",
    "\n",
    "print(\"Dropping duplicate images in ground truth\")\n",
    "df_groundtruth = df_groundtruth[df_groundtruth.image_name.isin(img_to_drop) == False]\n",
    "df_groundtruth.to_csv(\"data/ISIC_2020_Training_GroundTruth_v2.csv\")\n",
    "print(\"After dropping the duplicates, there are %i images in total in the meta-data file ('ground-truth')\" %len(df_groundtruth.index))\n",
    "\n",
    "print(\"Deleting duplicate images from the hard-drive\")\n",
    "for img_name in img_to_drop:\n",
    "    filename = img_path + \"/\" + img_name + \".jpg\"\n",
    "    try:\n",
    "        os.remove(filename)\n",
    "    except IOError:\n",
    "        pass\n",
    "\n",
    "print(\"There are now %i images on the hard-drive\" %len([name for name in os.listdir(img_path) if os.path.isfile(os.path.join(img_path, name))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Test Validation split\n",
    "In the next step, the data will be split into 3 parts. \n",
    "\n",
    "<b>Training Set</b>\n",
    "* 80%\n",
    "* Used to train the learning algorithm\n",
    "\n",
    "<b>Validation</b>\n",
    "* Part of training set that is held out (10% of overall data)\n",
    "* Used to evaluate different algorithms and hyperparameter settings\n",
    "\n",
    "<b>Test</b>\n",
    "* 10%\n",
    "* Used to test the model and estimate ist performance in application\n",
    "* Will <b>not</b> be used for training under no circumstances\n",
    "\n",
    "After this step, the folder structure will be as followed:\n",
    "<pre>\n",
    "data_investigation.ipynb\n",
    "data\n",
    "|---ISIC_2020_Training_GroundTruth_v2_train.csv\n",
    "|---ISIC_2020_Training_GroundTruth_v2_test.csv\n",
    "|---ISIC_2020_Training_GroundTruth_v2_valid.csv\n",
    "|---train\n",
    "    |---ISIC_0099484.jpg\n",
    "    |---...\n",
    "|---test\n",
    "    |---ISIC_0077474.jpg\n",
    "    |---...\n",
    "|---valid\n",
    "    |---ISIC_0089570.jpg\n",
    "    |---...\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set includes 26160 samples\n",
      "The validation set includes 3270 samples\n",
      "The test set includes 3271 samples\n",
      "Writing test train and validation data into seperate csv files\n",
      "Finished writing test train and validation data into seperate csv files\n",
      "Sorting images on hard-drive into seperate folders\n",
      "Created new directory data/train\n",
      "Created new directory data/test\n",
      "Created new directory data/valid\n",
      "Finished sorting images on hard-drive into seperate folders\n",
      "Removing no longer needed files\n",
      "Finished removing no longer needed files\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "random_state = 42\n",
    "df = pd.read_csv('data/ISIC_2020_Training_GroundTruth_v2.csv')\n",
    "\n",
    "X = df.drop(columns = ['diagnosis', 'benign_malignant', 'target']).copy()\n",
    "y = df[['diagnosis', 'benign_malignant', 'target']]\n",
    "\n",
    "train_size=0.8 # 80% training set\n",
    "X_train, X_remaining, y_train, y_remaining = train_test_split(X,y, \n",
    "                                                              train_size=train_size, \n",
    "                                                              random_state=random_state)\n",
    "\n",
    "test_size = 0.5 # 50% of remaining 20% -> 10%\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_remaining, y_remaining, \n",
    "                                                    test_size=test_size, \n",
    "                                                    random_state=random_state)\n",
    "\n",
    "print(\"The training set includes %i samples\" %len(X_train.index))\n",
    "print(\"The validation set includes %i samples\" %len(X_valid.index))\n",
    "print(\"The test set includes %i samples\" %len(X_test.index))\n",
    "\n",
    "print(\"Writing test train and validation data into seperate csv files\")\n",
    "\n",
    "train = pd.concat([X_train, y_train], axis=1, join='inner')\n",
    "valid = pd.concat([X_valid, y_valid], axis=1, join='inner')\n",
    "test = pd.concat([X_test, y_test], axis=1, join='inner')\n",
    "\n",
    "train.to_csv(\"data/ISIC_2020_Training_GroundTruth_v2_train.csv\")\n",
    "valid.to_csv(\"data/ISIC_2020_Training_GroundTruth_v2_valid.csv\")\n",
    "test.to_csv(\"data/ISIC_2020_Training_GroundTruth_v2_test.csv\")\n",
    "\n",
    "print(\"Finished writing test train and validation data into seperate csv files\")\n",
    "\n",
    "train_img = X_train[\"image_name\"].values.tolist()\n",
    "test_img = X_test[\"image_name\"].values.tolist()\n",
    "valid_img = X_valid[\"image_name\"].values.tolist()\n",
    "\n",
    "print(\"Sorting images on hard-drive into seperate folders\")\n",
    "\n",
    "def sort_img(path, img_names):\n",
    "    print(\"Coping %s images\" %path)\n",
    "    dest = 'data/' + path\n",
    "    src = 'data/ISIC_2020_Training_JPEG/train'\n",
    "    if not os.path.exists(dest): \n",
    "        os.makedirs(dest)\n",
    "        print(\"Created new directory %s\" %dest)\n",
    "    for img_name in img_names:\n",
    "        fname = src + \"/\" + img_name + \".jpg\"\n",
    "        shutil.move(fname, dest)\n",
    "\n",
    "sort_img(\"train\", train_img)\n",
    "sort_img(\"test\", test_img)\n",
    "sort_img(\"valid\", valid_img)\n",
    "\n",
    "print(\"Finished sorting images on hard-drive into seperate folders\")\n",
    "\n",
    "print(\"Removing no longer needed files\")\n",
    "shutil.rmtree(\"data/ISIC_2020_Training_JPEG\")\n",
    "os.remove(\"data/ISIC_2020_Training_Duplicates.csv\")\n",
    "os.remove(\"data/ISIC_2020_Training_GroundTruth_v2.csv\")\n",
    "print(\"Finished removing no longer needed files\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1d01c6bf3e9d205d38e3a736a612358a4609254e46bf94dc685129c2f8b8b6c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melanoma Classification with a Random Model\n",
    "Shall be used for comparison with other models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up for importing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Random State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import random_state\n",
    "import numpy as np\n",
    "\n",
    "random_state = random_state() \n",
    "seed = np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_results = True\n",
    "on_cluster = False # there is some issue with h5py in the local env but it works on cluster so w/e\n",
    "export_folder =  f'results/Random_Model'\n",
    "\n",
    "date_format = \"%d%m%Y%H%M%S\" # timestamp format in exported files\n",
    "if export_results:\n",
    "    import datetime\n",
    "    import os\n",
    "    if not os.path.exists(export_folder): \n",
    "      os.makedirs(export_folder)\n",
    "      print(\"Created new directory %s\" %export_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### img size config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pixel = 1 # can be low because the image is ignored anyways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timer\n",
    "\n",
    "Start the timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_data = True\n",
    "base_path = \"data/30\" \n",
    "current_train_melanoma_percentage = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get image paths\n",
    "For developing models on the cluster the max_images parameter should be removed. Instead call the method get_all_img_paths(img_folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import get_all_img_paths, get_img_paths\n",
    "\n",
    "img_folder_train = base_path + \"/train\" + (\"_downsampled\" if downsampled_data else \"\")\n",
    "img_folder_test = base_path + \"/test\" + (\"_downsampled\" if downsampled_data else \"\")\n",
    "\n",
    "max_images_train = int(13653*1)\n",
    "max_images_test = int(5804*1)\n",
    "\n",
    "img_paths_train = get_img_paths(img_folder_train, max_images_train) \n",
    "img_paths_test = get_img_paths(img_folder_test, max_images_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data\n",
    "Loads the images specified in img_paths into a data frame. This includes resizing the images and flattening them into an array and may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import load_train_test\n",
    "\n",
    "groundtruth_file_train = base_path + \"/ISIC_2020_2019_train\" + (\"_downsampled\" if downsampled_data else \"\") + \".csv\" \n",
    "groundtruth_file_test = base_path + \"/ISIC_2020_2019_test\" + (\"_downsampled\" if downsampled_data else \"\") + \".csv\"\n",
    "\n",
    "# available options\n",
    "options = [\"sequential\", # first load train, then load test\n",
    "           \"parallel_train_test\", # load train and test parallel (load data within train and test sequential)\n",
    "           \"sequential_train_test_parallel_chunks\", # load first train, then test, but load the data within the sets parallel\n",
    "           \"parallel_fusion\" # run train and test parallel and parallely load data with train and test \n",
    "          ]\n",
    "\n",
    "# chose an option\n",
    "option = \"parallel_fusion\"\n",
    "\n",
    "df_train, df_test = load_train_test(img_paths_train, groundtruth_file_train, \n",
    "                                    img_paths_test, groundtruth_file_test, \n",
    "                                    option, img_pixel);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into target and predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import split_predictors_target\n",
    "\n",
    "X_train, y_train = split_predictors_target(df_train) \n",
    "X_test, y_test = split_predictors_target(df_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df_train)\n",
    "del(df_test)\n",
    "del(img_paths_train)\n",
    "del(img_paths_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "model = DummyClassifier(strategy='stratified', random_state=random_state)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timer\n",
    "Stop the timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = time.time()\n",
    "print(f'It took {stop - start} s to load the data and train the model')\n",
    "\n",
    "if export_results:\n",
    "    f = open(f'{export_folder}/overall_time_{datetime.datetime.now().strftime(date_format)}.txt', 'w')\n",
    "    f.write(f'Time it took : {stop - start} s')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_continuous = model.predict(X_test)\n",
    "y_pred_discrete = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "y_pred = y_pred_discrete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_pred, digits=4)\n",
    "print(f'\\nClassification_report=\\n{report}')\n",
    "\n",
    "if export_results:\n",
    "    file = open(export_folder + \"/classification_report_\"+datetime.datetime.now().strftime(date_format)+\".txt\", 'w')\n",
    "    file.write(report)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class_names = [\"no melanoma\", \"melanoma\"]\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "plot = sns.heatmap(cf, annot= True, fmt=\".0f\",\n",
    "           xticklabels = class_names,\n",
    "           yticklabels = class_names)\n",
    "plot.set(xlabel='Prediction', ylabel='Actual')\n",
    "\n",
    "if export_results:\n",
    "    plot.get_figure().savefig(export_folder + '/confusion_matrix_' + datetime.datetime.now().strftime(date_format) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

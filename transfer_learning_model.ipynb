{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9ee9c3b",
   "metadata": {},
   "source": [
    "# Melanoma Classification with MLP Model\n",
    "\n",
    "In this notebook, a simple neural network based on the melanoma dataset will be build in order to assess initial performance.\n",
    "The notebook works with data previously saved to the disk. To create this script, the model template was used.\n",
    "\n",
    "The script that should be performed before this is the script: data_preparation_20192020.ipynb\n",
    "\n",
    "\n",
    "<b>Running the script on cluster</b>\n",
    "Please keep in mind the following\n",
    "1. Load ALL images rather than a subset by changing to get_all_img_paths(img_folder) in Step 2 (get image paths \n",
    "2. The path to the data can be modified in Step 2 (get image paths + load data)\n",
    "3. Make sure export is set to true\n",
    "4. Save the results that are stored in the export folder and upload them seperately on google drive or github. The folder \"export\" is not tracked on github!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74834a6a",
   "metadata": {},
   "source": [
    "## 1. Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a374ccfc",
   "metadata": {},
   "source": [
    "#### Set up for importing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e169495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b87b3e",
   "metadata": {},
   "source": [
    " #### Random State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2849c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import random_state\n",
    "random_state = random_state() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58472fd4",
   "metadata": {},
   "source": [
    "#### Export Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137e38dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_results = True\n",
    "on_cluster = False # there is some issue with h5py in the local env but it works on cluster so w/e\n",
    "export_folder = f'export'\n",
    "\n",
    "date_format = \"%d%m%Y%H%M%S\" # timestamp format in exported files\n",
    "if export_results:\n",
    "    import datetime\n",
    "    import os\n",
    "    if not os.path.exists(export_folder): \n",
    "      os.makedirs(export_folder)\n",
    "      print(\"Created new directory %s\" %export_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23012d0-ffa4-46a1-896e-f3c178b852ce",
   "metadata": {},
   "source": [
    "#### Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9c16cd-e497-439f-87ec-d54946dfb556",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pixel = 224 # default : 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1b52a6",
   "metadata": {},
   "source": [
    "#### Timer\n",
    "\n",
    "Start the timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a317ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cad230",
   "metadata": {},
   "source": [
    "## 2. Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11451395-a8cd-4da6-81b7-6f8c10d17a6a",
   "metadata": {},
   "source": [
    "#### Data config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a235d4-b3e4-49ec-9d90-ed1471a81a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_data = True\n",
    "base_path = \"data\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ce42c7",
   "metadata": {},
   "source": [
    "#### Get image paths\n",
    "For developing models on the cluster the max_images parameter should be removed. Instead call the method get_all_img_paths(img_folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89398eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import get_all_img_paths, get_img_paths\n",
    "\n",
    "img_folder_train = base_path + \"/train\" \n",
    "img_folder_test = base_path + \"/test\"\n",
    "max_images_train = 800\n",
    "max_images_test = 100\n",
    "\n",
    "img_paths_train = get_img_paths(img_folder_train, max_images_train) \n",
    "img_paths_test = get_img_paths(img_folder_test, max_images_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c9cbbc",
   "metadata": {},
   "source": [
    "#### Load data\n",
    "Loads the images specified in img_paths into a data frame. This includes resizing the images and flattening them into an array and may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831f3a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import load_train_test\n",
    "\n",
    "groundtruth_file_train = base_path + \"/ISIC_2020_2019_train.csv\" \n",
    "groundtruth_file_test = base_path + \"/ISIC_2020_2019_test.csv\"\n",
    "\n",
    "# available options\n",
    "options = [\"sequential\", # first load train, then load test\n",
    "           \"parallel_train_test\", # load train and test parallel (load data within train and test sequential)\n",
    "           \"sequential_train_test_parallel_chunks\", # load first train, then test, but load the data within the sets parallel\n",
    "           \"parallel_fusion\" # run train and test parallel and parallely load data with train and test \n",
    "          ]\n",
    "\n",
    "# chose an option\n",
    "option = \"parallel_fusion\"\n",
    "\n",
    "df_train, df_test = load_train_test(img_paths_train, groundtruth_file_train, \n",
    "                                    img_paths_test, groundtruth_file_test, \n",
    "                                    option, img_pixel);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292b49b5",
   "metadata": {},
   "source": [
    "#### Split into target and predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bf5831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import split_predictors_target\n",
    "\n",
    "X_train, y_train = split_predictors_target(df_train) \n",
    "X_test, y_test = split_predictors_target(df_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0edfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import unflatten_images_df\n",
    "\n",
    "# I changed the shape of input data because of InceptionV3 requirements\n",
    "X_train_flat = X_train\n",
    "X_test_flat = X_test\n",
    "X_train = unflatten_images_df(X_train)\n",
    "X_test = unflatten_images_df(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62dd000-3499-4e87-b37c-fbb1efd76d13",
   "metadata": {},
   "source": [
    "#### Delete some no longer needed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ca928b-c6ee-4b75-8883-b1b83185e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df_train)\n",
    "del(df_test)\n",
    "del(img_paths_train)\n",
    "del(img_paths_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb32203b",
   "metadata": {},
   "source": [
    "## 3. Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc672f2",
   "metadata": {},
   "source": [
    "Trying out a few transfer models Inception, VGG16, ResNet50, EfficientNetB0, EfficientNetB6.\n",
    "The results are in \\Transfer_Learning\\transfer_learning_results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd83cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers, losses, activations, models\n",
    "from tensorflow.keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Concatenate\n",
    "from tensorflow.keras.metrics import Recall\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import efficientnet.tfkeras as efn\n",
    "\n",
    "\n",
    "#from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "#base_model = InceptionV3(weights='imagenet', include_top=False, input_shape = (224,224,3)) \n",
    "#base_model.trainable = False\n",
    "#base_model.layers.pop()\n",
    "#base_model.layers.pop()\n",
    "#base_model.layers.pop()\n",
    "#add_model = Sequential()\n",
    "#add_model.add(base_model)\n",
    "#add_model.add(Flatten())\n",
    "#add_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#base_model = VGG16(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')\n",
    "#base_model.trainable = False\n",
    "#add_model = Sequential()\n",
    "#add_model.add(base_model)\n",
    "#add_model.add(Dense(512, activation='relu'))\n",
    "#add_model.add(Dropout(0.5))\n",
    "#add_model.add(Flatten())\n",
    "#add_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#base_model. = ResNet50(include_top=False, weights='imagenet', pooling='max')\n",
    "#base_model.trainable = False\n",
    "#add_model = Sequential()\n",
    "#add_model.add(base_model)\n",
    "#add_model.add(Flatten())\n",
    "#add_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#base_model = efn.EfficientNetB0(input_shape = (224,224, 3), include_top = False, weights = 'imagenet')\n",
    "#base_model.trainable = False\n",
    "#add_model = Sequential()\n",
    "#add_model.add(base_model)\n",
    "#add_model.add(Dense(1024, activation=\"relu\"))\n",
    "#add_model.add(Dropout(0.5))\n",
    "#add_model.add(Flatten())\n",
    "#add_model.add(Dense(1, activation='sigmoid'))\n",
    "#model = add_model\n",
    "\n",
    "#add_model = Sequential()\n",
    "#base_model = efn.EfficientNetB0(input_shape = (224,224, 3), include_top = False, weights = 'imagenet')\n",
    "#base_model.trainable = False\n",
    "#add_model.add(base_model)\n",
    "#add_model.add(Flatten())\n",
    "#add_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#add_model = Sequential()\n",
    "#base_model = efn.EfficientNetB6(input_shape=(224,224, 3),weights='imagenet',include_top=False)\n",
    "#base_model.trainable = False\n",
    "#add_model.add(base_model)\n",
    "#add_model.add(GlobalAveragePooling2D())\n",
    "#add_model.add(Dense(512, activation= 'relu'))\n",
    "#add_model.add(Dropout(0.25))\n",
    "#add_model.add(Flatten())\n",
    "#add_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "add_model = Sequential()\n",
    "base_model = efn.EfficientNetB6(input_shape=(224,224, 3),weights='imagenet',include_top=False)\n",
    "base_model.trainable = False\n",
    "add_model.add(base_model)\n",
    "add_model.add(Flatten())\n",
    "add_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model = add_model\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Nadam(), metrics=['accuracy', Recall(name=\"recall\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f376987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=32, epochs=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05da414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ef83fb-eca6-441d-9c40-e73488919936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store model\n",
    "if export_results and on_cluster:\n",
    "    model.save(export_folder + \"/model_\"+datetime.datetime.now().strftime(date_format)+\".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83fe768",
   "metadata": {},
   "source": [
    "#### Timer\n",
    "Stop the timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba1cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = time.time()\n",
    "print(f'It took {stop - start} s to load the data and train the model')\n",
    "\n",
    "if export_results:\n",
    "    f = open(f'{export_folder}/overall_time.txt', 'w')\n",
    "    f.write(f'Time it took : {stop - start} s')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6772cb6d",
   "metadata": {},
   "source": [
    "## 4. Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d0c8c5",
   "metadata": {},
   "source": [
    "#### Evaluate loss and accuracy during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d551259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "_, train_acc, train_recall = model.evaluate(X_train, y_train)\n",
    "_, test_acc, test_recall  = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Accuracy\\tTrain: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "print('Recall\\tTrain: %.3f, Test: %.3f' % (train_recall, test_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a08980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "_, axs = pyplot.subplots(3, 1, figsize=(20,15))\n",
    "\n",
    "# plot loss during training\n",
    "axs[0].plot(history.history['loss'], label='train')\n",
    "axs[0].plot(history.history['val_loss'], label='test')\n",
    "axs[0].set_title(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "# plot accuracy during training\n",
    "axs[1].plot(history.history['accuracy'], label='train')\n",
    "axs[1].plot(history.history['val_accuracy'], label='test')\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "axs[1].legend()\n",
    "\n",
    "# plot recall during training\n",
    "axs[2].plot(history.history['recall'], label='train')\n",
    "axs[2].plot(history.history['val_recall'], label='test')\n",
    "axs[2].set_title(\"Recall\")\n",
    "axs[2].legend()\n",
    "\n",
    "if export_results:\n",
    "    pyplot.savefig(export_folder + \"/loss_and_accuracy_during_training_\"+datetime.datetime.now().strftime(date_format)+\".png\")\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78ef81c",
   "metadata": {},
   "source": [
    "#### Predict test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ff1a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_continuous = model.predict(X_test)\n",
    "y_pred_discrete = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "y_pred = y_pred_discrete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98d085c",
   "metadata": {},
   "source": [
    "#### Print report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189438bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_pred, digits=4)\n",
    "print(f'\\nClassification_report=\\n{report}')\n",
    "\n",
    "if export_results:\n",
    "    file = open(export_folder + \"/classification_report_inception_\"+datetime.datetime.now().strftime(date_format)+\".txt\", 'w')\n",
    "    file.write(report)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dbaccd",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9843dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class_names = [\"no melanoma\", \"melanoma\"]\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "plot = sns.heatmap(cf, annot= True, fmt=\".0f\",\n",
    "           xticklabels = class_names,\n",
    "           yticklabels = class_names)\n",
    "plot.set(xlabel='Prediction', ylabel='Actual')\n",
    "\n",
    "if export_results:\n",
    "    plot.get_figure().savefig(export_folder + '/confusion_matrix_' + datetime.datetime.now().strftime(date_format) + \".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0434eba9",
   "metadata": {},
   "source": [
    "#### Display images and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402d1c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import display_results\n",
    "\n",
    "X_train = X_train_flat\n",
    "X_test = X_train_flat\n",
    "\n",
    "plt_all = display_results(X_test, y_pred, y_test, 15, img_pixel)\n",
    "\n",
    "if export_results:\n",
    "    plt_all.savefig(export_folder + \"/classification_results_\"+datetime.datetime.now().strftime(date_format)+\".png\")\n",
    "\n",
    "plt_all.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d501bb2f",
   "metadata": {},
   "source": [
    "#### Display wrongly classified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32025e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import display_interesting_results\n",
    "\n",
    "plt_wrong = display_interesting_results(X_test, y_pred, y_test, img_pixel=img_pixel)\n",
    "\n",
    "if export_results:\n",
    "    plt_wrong.savefig(export_folder + \"/incorrect_classification_results_\"+datetime.datetime.now().strftime(date_format)+\".png\")\n",
    "    \n",
    "plt_wrong.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105b4757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

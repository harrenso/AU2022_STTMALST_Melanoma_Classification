{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9ee9c3b",
   "metadata": {},
   "source": [
    "# Melanoma Classification with MLP Model\n",
    "\n",
    "In this notebook, a simple neural network based on the melanoma dataset will be build in order to assess initial performance.\n",
    "The notebook works with data previously saved to the disk. To create this script, the model template was used.\n",
    "\n",
    "The script that should be performed before this is the script: data_preparation_20192020.ipynb\n",
    "\n",
    "\n",
    "<b>Running the script on cluster</b>\n",
    "Please keep in mind the following\n",
    "1. Load ALL images rather than a subset by changing to get_all_img_paths(img_folder) in Step 2 (get image paths \n",
    "2. The path to the data can be modified in Step 2 (get image paths + load data)\n",
    "3. Make sure export is set to true\n",
    "4. Save the results that are stored in the export folder and upload them seperately on google drive or github. The folder \"export\" is not tracked on github!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74834a6a",
   "metadata": {},
   "source": [
    "## 1. Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a374ccfc",
   "metadata": {},
   "source": [
    "#### Set up for importing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e169495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505e8d1b-9d3a-4954-bac6-77e21599aba2",
   "metadata": {},
   "source": [
    "#### Install efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3af71787-2036-4385-863f-0d8fe6d2f00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: efficientnet in /home/stmal01e22/.local/lib/python3.9/site-packages (1.1.1)\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /home/stmal01e22/.local/lib/python3.9/site-packages (from efficientnet) (1.0.8)\n",
      "Requirement already satisfied: scikit-image in /opt/anaconda-2022.05/lib/python3.9/site-packages (from efficientnet) (0.19.2)\n",
      "Requirement already satisfied: h5py in /opt/anaconda-2022.05/lib/python3.9/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.7.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/anaconda-2022.05/lib/python3.9/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/anaconda-2022.05/lib/python3.9/site-packages (from scikit-image->efficientnet) (1.7.3)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/anaconda-2022.05/lib/python3.9/site-packages (from scikit-image->efficientnet) (2.7.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda-2022.05/lib/python3.9/site-packages (from scikit-image->efficientnet) (21.3)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/anaconda-2022.05/lib/python3.9/site-packages (from scikit-image->efficientnet) (2.9.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /opt/anaconda-2022.05/lib/python3.9/site-packages (from scikit-image->efficientnet) (9.0.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/anaconda-2022.05/lib/python3.9/site-packages (from scikit-image->efficientnet) (1.3.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/anaconda-2022.05/lib/python3.9/site-packages (from scikit-image->efficientnet) (2021.7.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda-2022.05/lib/python3.9/site-packages (from packaging>=20.0->scikit-image->efficientnet) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "os.system(\"pip install efficientnet\")\n",
    "\n",
    "import efficientnet.tfkeras as efn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b87b3e",
   "metadata": {},
   "source": [
    " #### Random State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2849c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import random_state\n",
    "random_state = random_state() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58472fd4",
   "metadata": {},
   "source": [
    "#### Export Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "137e38dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_results = True\n",
    "on_cluster = False # there is some issue with h5py in the local env but it works on cluster so w/e\n",
    "export_folder = f'Transfer_Learning/Cluster/091122-30percent-50'\n",
    "\n",
    "date_format = \"%d%m%Y%H%M%S\" # timestamp format in exported files\n",
    "if export_results:\n",
    "    import datetime\n",
    "    import os\n",
    "    if not os.path.exists(export_folder): \n",
    "      os.makedirs(export_folder)\n",
    "      print(\"Created new directory %s\" %export_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23012d0-ffa4-46a1-896e-f3c178b852ce",
   "metadata": {},
   "source": [
    "#### Resolution Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e9c16cd-e497-439f-87ec-d54946dfb556",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pixel = 224 # default : 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1b52a6",
   "metadata": {},
   "source": [
    "#### Timer\n",
    "\n",
    "Start the timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99a317ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cad230",
   "metadata": {},
   "source": [
    "## 2. Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11451395-a8cd-4da6-81b7-6f8c10d17a6a",
   "metadata": {},
   "source": [
    "#### Data config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3a235d4-b3e4-49ec-9d90-ed1471a81a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_data = True\n",
    "base_path = \"data/30\" \n",
    "current_train_melanoma_percentage = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ce42c7",
   "metadata": {},
   "source": [
    "#### Get image paths\n",
    "For developing models on the cluster the max_images parameter should be removed. Instead call the method get_all_img_paths(img_folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c89398eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import get_all_img_paths, get_img_paths\n",
    "\n",
    "img_folder_train = base_path + \"/train\" + (\"_downsampled\" if downsampled_data else \"\")\n",
    "img_folder_test = base_path + \"/test\" + (\"_downsampled\" if downsampled_data else \"\")\n",
    "\n",
    "max_images_train = int(13653*0.5)\n",
    "max_images_test = int(5804*0.5)\n",
    "\n",
    "img_paths_train = get_img_paths(img_folder_train, max_images_train) \n",
    "img_paths_test = get_img_paths(img_folder_test, max_images_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c9cbbc",
   "metadata": {},
   "source": [
    "#### Load data\n",
    "Loads the images specified in img_paths into a data frame. This includes resizing the images and flattening them into an array and may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "831f3a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num images per thread 463\n",
      "start loading train\n",
      "start thread #0 for train\n",
      "start loading test\n",
      "start thread #0 for test\n",
      "start thread #1 for test\n",
      "start thread #1 for train\n",
      "start thread #2 for test\n",
      "start thread #3 for test\n",
      "start thread #2 for train\n",
      "start thread #4 for test\n",
      "start thread #3 for train\n",
      "start thread #5 for test\n",
      "start thread #4 for train\n",
      "start thread #5 for train\n",
      "start thread #6 for train\n",
      "start thread #7 for train\n",
      "start thread #8 for train\n",
      "start thread #9 for train\n",
      "start thread #10 for train\n",
      "start thread #11 for train\n",
      "start thread #12 for train\n",
      "start thread #13 for train\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3647725/2127877704.py\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0moption\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"parallel_fusion\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m df_train, df_test = load_train_test(img_paths_train, groundtruth_file_train, \n\u001b[0m\u001b[1;32m     18\u001b[0m                                     \u001b[0mimg_paths_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroundtruth_file_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                     option, img_pixel);\n",
      "\u001b[0;32m~/sttmalst_melanoma_classification_2022/utilities.py\u001b[0m in \u001b[0;36mload_train_test\u001b[0;34m(img_paths_train, groundtruth_file_train, img_paths_test, groundtruth_file_test, option, img_pixel)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mt1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0mt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda-2022.05/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1053\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1054\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda-2022.05/lib/python3.9/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1074\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from utilities import load_train_test\n",
    "\n",
    "groundtruth_file_train = base_path + \"/ISIC_2020_2019_train\" + (\"_downsampled\" if downsampled_data else \"\") + \".csv\" \n",
    "groundtruth_file_test = base_path + \"/ISIC_2020_2019_test\" + (\"_downsampled\" if downsampled_data else \"\") + \".csv\"\n",
    "\n",
    "\n",
    "# available options\n",
    "options = [\"sequential\", # first load train, then load test\n",
    "           \"parallel_train_test\", # load train and test parallel (load data within train and test sequential)\n",
    "           \"sequential_train_test_parallel_chunks\", # load first train, then test, but load the data within the sets parallel\n",
    "           \"parallel_fusion\" # run train and test parallel and parallely load data with train and test \n",
    "          ]\n",
    "\n",
    "# chose an option\n",
    "option = \"parallel_fusion\"\n",
    "\n",
    "df_train, df_test = load_train_test(img_paths_train, groundtruth_file_train, \n",
    "                                    img_paths_test, groundtruth_file_test, \n",
    "                                    option, img_pixel);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292b49b5",
   "metadata": {},
   "source": [
    "#### Split into target and predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bf5831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import split_predictors_target\n",
    "\n",
    "X_train, y_train = split_predictors_target(df_train) \n",
    "X_test, y_test = split_predictors_target(df_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0edfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import unflatten_images_df\n",
    "\n",
    "# I changed the shape of input data because of InceptionV3 requirements\n",
    "X_train_flat = X_train\n",
    "X_test_flat = X_test\n",
    "X_train = unflatten_images_df(X_train, img_pixel=img_pixel)\n",
    "X_test = unflatten_images_df(X_test, img_pixel=img_pixel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62dd000-3499-4e87-b37c-fbb1efd76d13",
   "metadata": {},
   "source": [
    "#### Delete some no longer needed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ca928b-c6ee-4b75-8883-b1b83185e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df_train)\n",
    "del(df_test)\n",
    "del(img_paths_train)\n",
    "del(img_paths_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb32203b",
   "metadata": {},
   "source": [
    "## 3. Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc672f2",
   "metadata": {},
   "source": [
    "Trying out a few transfer models Inception, VGG16, ResNet50, EfficientNetB0, EfficientNetB6.\n",
    "The results are in \\Transfer_Learning\\transfer_learning_results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd83cf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import optimizers, losses, activations, models\n",
    "from tensorflow.keras.layers import Convolution2D, Dense, Input, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Concatenate\n",
    "from tensorflow.keras.metrics import Recall\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "\n",
    "\n",
    "#from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "#base_model = InceptionV3(weights='imagenet', include_top=False, input_shape = (224,224,3)) \n",
    "#base_model.trainable = False\n",
    "#base_model.layers.pop()\n",
    "#base_model.layers.pop()\n",
    "#base_model.layers.pop()\n",
    "#add_model = Sequential()\n",
    "#add_model.add(base_model)\n",
    "#add_model.add(Flatten())\n",
    "#add_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#base_model = VGG16(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')\n",
    "#base_model.trainable = False\n",
    "#add_model = Sequential()\n",
    "#add_model.add(base_model)\n",
    "#add_model.add(Dense(512, activation='relu'))\n",
    "#add_model.add(Dropout(0.5))\n",
    "#add_model.add(Flatten())\n",
    "#add_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#base_model. = ResNet50(include_top=False, weights='imagenet', pooling='max')\n",
    "#base_model.trainable = False\n",
    "#add_model = Sequential()\n",
    "#add_model.add(base_model)\n",
    "#add_model.add(Flatten())\n",
    "#add_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#base_model = efn.EfficientNetB0(input_shape = (224,224, 3), include_top = False, weights = 'imagenet')\n",
    "#base_model.trainable = False\n",
    "#add_model = Sequential()\n",
    "#add_model.add(base_model)\n",
    "#add_model.add(Dense(1024, activation=\"relu\"))\n",
    "#add_model.add(Dropout(0.5))\n",
    "#add_model.add(Flatten())\n",
    "#add_model.add(Dense(1, activation='sigmoid'))\n",
    "#model = add_model\n",
    "\n",
    "#add_model = Sequential()\n",
    "#base_model = efn.EfficientNetB0(input_shape = (224,224, 3), include_top = False, weights = 'imagenet')\n",
    "#base_model.trainable = False\n",
    "#add_model.add(base_model)\n",
    "#add_model.add(Flatten())\n",
    "#add_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "#add_model = Sequential()\n",
    "#base_model = efn.EfficientNetB6(input_shape=(224,224, 3),weights='imagenet',include_top=False)\n",
    "#base_model.trainable = False\n",
    "#add_model.add(base_model)\n",
    "#add_model.add(GlobalAveragePooling2D())\n",
    "#add_model.add(Dense(512, activation= 'relu'))\n",
    "#add_model.add(Dropout(0.25))\n",
    "#add_model.add(Flatten())\n",
    "#add_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "add_model = Sequential()\n",
    "base_model = efn.EfficientNetB6(input_shape=(224,224, 3),weights='imagenet',include_top=False)\n",
    "base_model.trainable = False\n",
    "add_model.add(base_model)\n",
    "add_model.add(Flatten())\n",
    "add_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model = add_model\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Nadam(), metrics=['accuracy', Recall(name=\"recall\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f376987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau \n",
    "\n",
    "melanoma_weight = (1/current_train_melanoma_percentage)/2\n",
    "class_weight = {0: 1.,\n",
    "                1: melanoma_weight,}\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    batch_size=32, epochs=100,\n",
    "                    callbacks=[EarlyStopping(patience=10), lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05da414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ef83fb-eca6-441d-9c40-e73488919936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store model\n",
    "if export_results and on_cluster:\n",
    "    model.save(export_folder + \"/model_\"+datetime.datetime.now().strftime(date_format)+\".h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83fe768",
   "metadata": {},
   "source": [
    "#### Timer\n",
    "Stop the timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ba1cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = time.time()\n",
    "print(f'It took {stop - start} s to load the data and train the model')\n",
    "\n",
    "if export_results:\n",
    "    f = open(f'{export_folder}/overall_time.txt', 'w')\n",
    "    f.write(f'Time it took : {stop - start} s')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6772cb6d",
   "metadata": {},
   "source": [
    "## 4. Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d0c8c5",
   "metadata": {},
   "source": [
    "#### Evaluate loss and accuracy during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d551259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "_, train_acc, train_recall = model.evaluate(X_train, y_train)\n",
    "_, test_acc, test_recall  = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Accuracy\\tTrain: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
    "print('Recall\\tTrain: %.3f, Test: %.3f' % (train_recall, test_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a08980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "_, axs = pyplot.subplots(3, 1, figsize=(20,15))\n",
    "\n",
    "# plot loss during training\n",
    "axs[0].plot(history.history['loss'], label='train')\n",
    "axs[0].plot(history.history['val_loss'], label='test')\n",
    "axs[0].set_title(\"Loss\")\n",
    "axs[0].legend()\n",
    "\n",
    "# plot accuracy during training\n",
    "axs[1].plot(history.history['accuracy'], label='train')\n",
    "axs[1].plot(history.history['val_accuracy'], label='test')\n",
    "axs[1].set_title(\"Accuracy\")\n",
    "axs[1].legend()\n",
    "\n",
    "# plot recall during training\n",
    "axs[2].plot(history.history['recall'], label='train')\n",
    "axs[2].plot(history.history['val_recall'], label='test')\n",
    "axs[2].set_title(\"Recall\")\n",
    "axs[2].legend()\n",
    "\n",
    "if export_results:\n",
    "    pyplot.savefig(export_folder + \"/loss_and_accuracy_during_training_\"+datetime.datetime.now().strftime(date_format)+\".png\")\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78ef81c",
   "metadata": {},
   "source": [
    "#### Predict test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ff1a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_continuous = model.predict(X_test)\n",
    "y_pred_discrete = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "y_pred = y_pred_discrete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98d085c",
   "metadata": {},
   "source": [
    "#### Print report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189438bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_pred, digits=4)\n",
    "print(f'\\nClassification_report=\\n{report}')\n",
    "\n",
    "if export_results:\n",
    "    file = open(export_folder + \"/classification_report_inception_\"+datetime.datetime.now().strftime(date_format)+\".txt\", 'w')\n",
    "    file.write(report)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dbaccd",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9843dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class_names = [\"no melanoma\", \"melanoma\"]\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "plot = sns.heatmap(cf, annot= True, fmt=\".0f\",\n",
    "           xticklabels = class_names,\n",
    "           yticklabels = class_names)\n",
    "plot.set(xlabel='Prediction', ylabel='Actual')\n",
    "\n",
    "if export_results:\n",
    "    plot.get_figure().savefig(export_folder + '/confusion_matrix_' + datetime.datetime.now().strftime(date_format) + \".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0434eba9",
   "metadata": {},
   "source": [
    "#### Display images and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402d1c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import display_results\n",
    "\n",
    "X_train = X_train_flat\n",
    "X_test = X_train_flat\n",
    "\n",
    "plt_all = display_results(X_test, y_pred, y_test, 15, img_pixel)\n",
    "\n",
    "if export_results:\n",
    "    plt_all.savefig(export_folder + \"/classification_results_\"+datetime.datetime.now().strftime(date_format)+\".png\")\n",
    "\n",
    "plt_all.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d501bb2f",
   "metadata": {},
   "source": [
    "#### Display wrongly classified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32025e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import display_interesting_results\n",
    "\n",
    "plt_wrong = display_interesting_results(X_test, y_pred, y_test, img_pixel=img_pixel)\n",
    "\n",
    "if export_results:\n",
    "    plt_wrong.savefig(export_folder + \"/incorrect_classification_results_\"+datetime.datetime.now().strftime(date_format)+\".png\")\n",
    "    \n",
    "plt_wrong.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105b4757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

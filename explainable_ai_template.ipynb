{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffa9a720",
   "metadata": {},
   "source": [
    "# Explainable AI\n",
    "this script includes the scaffold needed to test out explainable AI for the melanoma classification project. access to the following data is given\n",
    "- a ML model\n",
    "- input shape expected by that model\n",
    "- a single image and a corresponding prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b376665d",
   "metadata": {},
   "source": [
    "## Import utils script setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8eae243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83b01a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install --user tensorflow==2.8.3\n",
    "#%pip install --user keras==2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac1c43d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.3\n",
      "2.8.0\n",
      "1.21.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf; print(tf.__version__)\n",
    "import keras; print(keras.__version__)\n",
    "import numpy; print(numpy.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f3de1c",
   "metadata": {},
   "source": [
    "## Getting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb3860f",
   "metadata": {},
   "source": [
    "#### Load model into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c60aaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from efficientnet.tfkeras import EfficientNetB0\n",
    "\n",
    "# NOTE: a different model which takes non-flattened data is needed. such a model is currently not on the cluster\n",
    "model_path = \"explain_ai_model/dummy_model.h5\"\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f430e1c3",
   "metadata": {},
   "source": [
    "#### Investigate expected shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28ed83bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "input_shape = model.get_config()[\"layers\"][0][\"config\"][\"batch_input_shape\"]\n",
    "expect_flattened_input = len(input_shape) == 2\n",
    "img_pixel = int(sqrt(input_shape[1]/3) if expect_flattened_input else input_shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d16d754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model expects images with size 224*224 which are not flattened out\n"
     ]
    }
   ],
   "source": [
    "are_flat = \"are\" if expect_flattened_input else \"are not\"\n",
    "print(f\"the model expects images with size {img_pixel}*{img_pixel} which {are_flat} flattened out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eead22",
   "metadata": {},
   "source": [
    "## Load images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bcb084",
   "metadata": {},
   "source": [
    "#### Config on where to find the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58ca091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"data\" \n",
    "downsampled_data = False\n",
    "partition = \"test\"\n",
    "num_images = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "246dd893",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folder = base_path + \"/\" + partition + (\"_downsampled\" if downsampled_data else \"\")\n",
    "groundtruth_file = base_path + \"/ISIC_2020_2019_\" + partition + (\"_downsampled\" if downsampled_data else \"\") + \".csv\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086474bf",
   "metadata": {},
   "source": [
    "#### Getting image(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20e9aeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import get_img_paths, load_data, split_predictors_target, unflatten_images_df\n",
    "\n",
    "img_paths = get_img_paths(img_folder, num_images) \n",
    "df = load_data(img_paths, groundtruth_file, img_pixel=img_pixel)\n",
    "X, y = split_predictors_target(df) \n",
    "\n",
    "if not expect_flattened_input:\n",
    "    X = unflatten_images_df(X, img_pixel=img_pixel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45dbea2",
   "metadata": {},
   "source": [
    "# Hi Ren√©e\n",
    "at this point, \n",
    "- X includes a list of images which may or may not be flat depending on what the model expects. \n",
    "- y includes the correct labels\n",
    "- model includes the loaded ML model which should be used to make the predicitons.\n",
    "\n",
    "You can adjust the num of images display with num_images and the model used in model_path. the other stuff should (hopefully) be automatically adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc7e2cf",
   "metadata": {},
   "source": [
    "## Predict and display images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0628b3b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iterrows'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9540\\776112012.py\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;31m# output prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"Image {i+1}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iterrows'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "depth = 3\n",
    "\n",
    "# predict images\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "if expect_flattened_input:\n",
    "    i = 0\n",
    "    for img_name, img in X.iterrows():\n",
    "        # output prediction\n",
    "        title = f\"Image {i+1}\"\n",
    "        prediction = f\"Confidence that the image is melanoma: {y_pred[i][0]}\"\n",
    "        i+=1\n",
    "\n",
    "        # get image in correct format\n",
    "        img_to_display = img.to_numpy()\n",
    "        img_to_display = img_to_display.reshape(img_pixel,img_pixel,depth) # unflatten the image\n",
    "\n",
    "        # display image\n",
    "        plt.figure()\n",
    "        plt.imshow(img_to_display)\n",
    "        plt.title(prediction)\n",
    "        plt.suptitle(title, fontweight =\"bold\")\n",
    "else: \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0beec7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Version of tensorflow used: 2.8.3\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as c_map\n",
    "from IPython.display import Image, display\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications.xception import Xception, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "import lime\n",
    "from lime import lime_image\n",
    "from lime import submodular_pick\n",
    "\n",
    "from skimage.segmentation import mark_boundaries\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(f\" Version of tensorflow used: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fab3276",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_path => image that will be worked on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ef3207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image transformation of the example\n",
    "#IMG_SIZE = (299, 299)\n",
    "#def transform_image(image_path, size):\n",
    "#    '''\n",
    "#    Function to transform an image to normalized numpy array\n",
    "#    '''\n",
    "#    img = image.load_img(image_path, target_size=size)\n",
    "#    img = image.img_to_array(img)# Transforming the image to get the shape as [channel, height, width]\n",
    "#    img = np.expand_dims(img, axis=0) # Adding dimension to convert array into a batch of size (1,299,299,3)\n",
    "#    img = img/255.0 # normalizing the image to keep within the range of 0.0 to 1.0\n",
    "    \n",
    "#    return img\n",
    "\n",
    "#normalized_img = transform_image(image_path, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be7ca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_orig => predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4cc24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5df827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp = explainer.explain_instance(normalized_img[0], \n",
    "#                                 model.predict, \n",
    "#                                 top_labels=5, #might not need\n",
    "#                                 hide_color=0, \n",
    "#                                 num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4764fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def generate_prediction_sample(exp, exp_class, weight = 0.1, show_positive = True, hide_background = True):\n",
    "    '''\n",
    "    Method to display and highlight super-pixels used by the black-box model to make predictions\n",
    "    '''\n",
    "    plt.figure()\n",
    "    image, mask = exp.get_image_and_mask(exp_class, \n",
    "                                         positive_only=show_positive, \n",
    "                                         num_features=6, \n",
    "                                         hide_rest=hide_background,\n",
    "                                         min_weight=weight\n",
    "                                        )\n",
    "    plt.imshow(mark_boundaries(image, mask))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "#Heatmap\n",
    "#show how important each super-pixel is to get more granular explaianbility.\n",
    "def explanation_heatmap(exp, exp_class):\n",
    "    '''\n",
    "    Using heat-map to highlight the importance of each super-pixel for the model prediction\n",
    "    '''\n",
    "    plt.figure()\n",
    "    dict_heatmap = dict(exp.local_exp[exp_class])\n",
    "    heatmap = np.vectorize(dict_heatmap.get)(exp.segments) \n",
    "    plt.imshow(heatmap, cmap = 'RdBu', vmin  = -heatmap.max(), vmax = heatmap.max())\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0081b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for img_name, img in X.iterrows():\n",
    "    # output prediction\n",
    "    title = f\"Image {i+1}\"\n",
    "    prediction = f\"Confidence that the image is melanoma: {y_pred[i][0]}\"\n",
    "    i+=1\n",
    "        \n",
    "    # get image in correct format\n",
    "    img_to_display = img.to_numpy()\n",
    "\n",
    "    exp = explainer.explain_instance(img_to_display, \n",
    "                                 model.predict, \n",
    "                                 top_labels=5, #might not need\n",
    "                                 hide_color=0, \n",
    "                                 num_samples=1000)\n",
    "    if expect_flattened_input:\n",
    "        img_to_display = img_to_display.reshape(img_pixel,img_pixel,depth) # unflatten the image\n",
    "    \n",
    "    # display image\n",
    "    plt.figure()\n",
    "    plt.imshow(img_to_display)\n",
    "    plt.title(prediction)\n",
    "    plt.suptitle(title, fontweight =\"bold\")\n",
    "    \n",
    "    plt.imshow(exp.segments)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    generate_prediction_sample(exp, exp.top_labels[0], show_positive = True, hide_background = True)\n",
    "    \n",
    "    generate_prediction_sample(exp, exp.top_labels[0], show_positive = True, hide_background = False)\n",
    "    #highlight the contour of the superpixel and include the background\n",
    "    \n",
    "    generate_prediction_sample(exp, exp.top_labels[0], show_positive = False, hide_background = False)\n",
    "    #highlight the positive super-pixels and negative superpixels\n",
    "    \n",
    "    explanation_heatmap(exp, exp.top_labels[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

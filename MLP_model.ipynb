{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melanoma Classification Model - MLP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up for importing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Random State\n",
    " Please use the following random state for all methods that may take a random state in order to achieve reproducable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import random_state\n",
    "random_state = random_state() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export Config\n",
    "You may configure \n",
    "- whether the results shall be exported (export_results)\n",
    "- where the results will be exported to\n",
    "\n",
    "The default folder \"export\" will not be tracked by git in order to avoid flooding the repository with w.i.p. results. If you want to save a result on github, please rename it including the type of model and the date and move the picture to another folder :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_results = True\n",
    "on_cluster = False # there is some issue with h5py in the local env but it works on cluster so w/e\n",
    "export_folder = f'results/MLP_Model'\n",
    "\n",
    "date_format = \"%d%m%Y%H%M%S\" # timestamp format in exported files\n",
    "if export_results:\n",
    "    import datetime\n",
    "    import os\n",
    "    if not os.path.exists(export_folder): \n",
    "      os.makedirs(export_folder)\n",
    "      print(\"Created new directory %s\" %export_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resolution Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pixel = 224 # default : 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timer\n",
    "\n",
    "Start the timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampled_data = True\n",
    "base_path = \"data/30\" \n",
    "current_train_melanoma_percentage = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get image paths\n",
    "You may adjust the number of images loaded in order to run models more quickly on your private computer. Note hoewever that the less images you use the worse the predictions will likely be. \n",
    "\n",
    "For developing models on the cluster the max_images parameter should be removed. Instead call the method get_all_img_paths(img_folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import get_all_img_paths, get_img_paths\n",
    "\n",
    "img_folder_train = base_path + \"/train\" + (\"_downsampled\" if downsampled_data else \"\")\n",
    "img_folder_test = base_path + \"/test\" + (\"_downsampled\" if downsampled_data else \"\")\n",
    "\n",
    "max_images_train = int(13653*1)\n",
    "max_images_test = int(5804*1)\n",
    "\n",
    "img_paths_train = get_img_paths(img_folder_train, max_images_train) \n",
    "img_paths_test = get_img_paths(img_folder_test, max_images_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data\n",
    "Loads the images specified in img_paths into a data frame. This includes resizing the images and flattening them into an array and may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utilities import load_train_test\n",
    "\n",
    "groundtruth_file_train = base_path + \"/ISIC_2020_2019_train\" + (\"_downsampled\" if downsampled_data else \"\") + \".csv\" \n",
    "groundtruth_file_test = base_path + \"/ISIC_2020_2019_test\" + (\"_downsampled\" if downsampled_data else \"\") + \".csv\"\n",
    "\n",
    "\n",
    "# available options\n",
    "options = [\"sequential\", # first load train, then load test\n",
    "           \"parallel_train_test\", # load train and test parallel (load data within train and test sequential)\n",
    "           \"sequential_train_test_parallel_chunks\", # load first train, then test, but load the data within the sets parallel\n",
    "           \"parallel_fusion\" # run train and test parallel and parallely load data with train and test \n",
    "          ]\n",
    "\n",
    "# chose an option\n",
    "option = \"parallel_fusion\"\n",
    "\n",
    "df_train, df_test = load_train_test(img_paths_train, groundtruth_file_train, \n",
    "                                    img_paths_test, groundtruth_file_test, \n",
    "                                    option, img_pixel);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split into target and predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import split_predictors_target\n",
    "\n",
    "X_train, y_train = split_predictors_target(df_train) \n",
    "X_test, y_test = split_predictors_target(df_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "Put your model here! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if export_results and on_cluster:\n",
    "#    model.save(export_folder + \"/model_\"+datetime.datetime.now().strftime(date_format)+\".h5\")\n",
    "    \n",
    "    \n",
    "#'MLPClassifier' object has no attribute 'save'    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timer \n",
    "Stop the timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = time.time()\n",
    "print(f'It took {stop - start} s to load the data and train the model')\n",
    "\n",
    "if export_results:\n",
    "    f = open(f'{export_folder}/overall_time.txt', 'w')\n",
    "    f.write(f'Time it took : {stop - start} s')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict test set\n",
    "You may need to modify this depending on your model. Important thing is that after this step, the results of your classification should be stored in y_pred so that the following steps will work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_pred, digits=4)\n",
    "print(f'\\nClassification_report=\\n{report}')\n",
    "\n",
    "if export_results:\n",
    "    file = open(export_folder + \"/classification_report_\"+datetime.datetime.now().strftime(date_format)+\".txt\", 'w')\n",
    "    file.write(report)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class_names = [\"no melanoma\", \"melanoma\"]\n",
    "\n",
    "cf = confusion_matrix(y_test, y_pred)\n",
    "plot = sns.heatmap(cf, annot= True, fmt=\".0f\",\n",
    "           xticklabels = class_names,\n",
    "           yticklabels = class_names)\n",
    "plot.set(xlabel='Prediction', ylabel='Actual')\n",
    "\n",
    "if export_results:\n",
    "    plot.get_figure().savefig(export_folder + '/confusion_matrix_' + datetime.datetime.now().strftime(date_format) + \".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display images and predictions\n",
    "Note: you may pass a fourth parameter indicating the maximum images displayed. per default this parameter is set as 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import display_results\n",
    "\n",
    "plt_all = display_results(X_test, y_pred, y_test, 15, img_pixel, flat=True)\n",
    "\n",
    "if export_results:\n",
    "    plt_all.savefig(export_folder + \"/classification_results_\"+datetime.datetime.now().strftime(date_format)+\".png\")\n",
    "\n",
    "plt_all.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display wrongly classified images\n",
    "Note: you may pass a fourth parameter indicating the maximum images displayed. per default this parameter is set as 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import display_interesting_results\n",
    "\n",
    "plt_wrong = display_interesting_results(X_test, y_pred, y_test, img_pixel=img_pixel, flat=True)\n",
    "\n",
    "if export_results:\n",
    "    plt_wrong.savefig(export_folder + \"/incorrect_classification_results_\"+datetime.datetime.now().strftime(date_format)+\".png\")\n",
    "    \n",
    "plt_wrong.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
